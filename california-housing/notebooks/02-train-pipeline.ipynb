{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pipeline\n",
    "\n",
    "This notebook takes the train and test data and does the following:\n",
    "\n",
    "- Data processing (cleaning, feature engineering, scaling etc.) to prepare it for model training\n",
    "- Trains a simple model\n",
    "- Saves any artifacts that will be used during inference to disk\n",
    "\n",
    "> This process will likely be captured in a Pipeline asset on Highwind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "RANDOM_SEED = 42\n",
    "ARTIFACT_SAVE_DIR = \"../saved_model/\"\n",
    "TRAIN_DATA_PATH = \"../data/train.csv\"\n",
    "TEST_DATA_PATH = \"../data/test.csv\"\n",
    "TARGET_COLUMN = \"MedHouseVal\"\n",
    "MODEL_ARGS = {\n",
    "    \"alpha\": 0.01,\n",
    "    \"fit_intercept\": True,\n",
    "    \"random_state\": RANDOM_SEED\n",
    "}\n",
    "PUSH_TO_HF = True # Whether to push to Hugging Face Hub or not\n",
    "HF_REPO_NAME = \"MelioAI/california-housing\" # For pushing model to Hugging Face Hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruan/Documents/github/highwind-examples/california-housing/.train.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from skops import card, hub_utils\n",
    "from tempfile import mkdtemp, mkstemp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.2596</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.017657</td>\n",
       "      <td>1.006421</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>3.691814</td>\n",
       "      <td>32.71</td>\n",
       "      <td>-117.03</td>\n",
       "      <td>1.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.8125</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.473545</td>\n",
       "      <td>1.041005</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>1.738095</td>\n",
       "      <td>33.77</td>\n",
       "      <td>-118.16</td>\n",
       "      <td>3.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.1563</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.645833</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>915.0</td>\n",
       "      <td>2.723214</td>\n",
       "      <td>34.66</td>\n",
       "      <td>-120.48</td>\n",
       "      <td>1.726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.2596      33.0  5.017657   1.006421      2300.0  3.691814     32.71   \n",
       "1  3.8125      49.0  4.473545   1.041005      1314.0  1.738095     33.77   \n",
       "2  4.1563       4.0  5.645833   0.985119       915.0  2.723214     34.66   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -117.03        1.030  \n",
       "1    -118.16        3.821  \n",
       "2    -120.48        1.726  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X_train = train_df.copy()\n",
    "y_train = X_train.pop(TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (16512, 8)\n",
      "y_train: (16512,)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional steps\n",
    "\n",
    "Insert any optional data processing steps here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Add data cleaning here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Add feature engineering here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise scaler and scale train features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_model/scaler.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaler for later use\n",
    "save_scaler_path = os.path.join(ARTIFACT_SAVE_DIR, \"scaler.joblib\")\n",
    "joblib.dump(scaler, save_scaler_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Lasso(**MODEL_ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.01, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.01, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.01, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80095744,  0.12708701, -0.16275931,  0.20620745, -0.        ,\n",
       "       -0.03060176, -0.79011254, -0.75567379])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check learned model weights\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_model/model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model for later use\n",
    "save_model_path = os.path.join(ARTIFACT_SAVE_DIR, \"model.joblib\")\n",
    "joblib.dump(model, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Save to Hugging Face Hub\n",
    "\n",
    "Save trained model files to the Hugging Face Hub so that they can be downloaded later. In this step, we use the useful helper functions provided by the `skops` package.\n",
    "\n",
    "If `PUSH_TO_HF` is enabled (see top of this notebook), this section will execute. Remember to log into Hugging Face with the CLI by running: `huggingface-cli login` otherwise this section won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make temporary local repo dir\n",
    "local_repo = Path(\"../hf-repo\") # mkdtemp(prefix=\"skops-\")\n",
    "\n",
    "if PUSH_TO_HF:\n",
    "\n",
    "    # Initialise HF repo\n",
    "    hub_utils.init(\n",
    "        model=Path(save_model_path),\n",
    "        requirements=[\n",
    "            f\"scikit-learn=={sklearn.__version__}\",\n",
    "            f\"joblib=={joblib.__version__}\"\n",
    "        ],\n",
    "        dst=local_repo,\n",
    "        task=\"tabular-classification\",\n",
    "        data=X_train.head(),\n",
    "        model_format=\"pickle\"\n",
    "    )\n",
    "\n",
    "    # Add feature scaler to repo\n",
    "    hub_utils.add_files(save_scaler_path, dst=local_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PUSH_TO_HF:\n",
    "\n",
    "    # Create and populate basic model card\n",
    "    model_card = card.Card(model=model)\n",
    "    metadata = card.metadata_from_config(local_repo / \"config.json\")\n",
    "    \n",
    "    # Add model card detail\n",
    "    limitations = (\n",
    "        \"This model is made for the purposes of showing how to use Highwind only.\"\n",
    "    )\n",
    "    model_description = (\n",
    "        \"This is a linear regression model trained on California housing dataset. This model could be\"\n",
    "        \" used to predict median price of a house in California, given certain features. This model is very basic and\"\n",
    "        \" should only be used as an example of how to use Highwind.\"\n",
    "    )\n",
    "    model_card_authors = \"MelioAI, ruanmelio\"\n",
    "    usage_code = \"\"\"\n",
    "```python\n",
    "import joblib\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Feature scaler\n",
    "hf_hub_download(\"MelioAI/california-housing\", \"scaler.joblib\")\n",
    "scaler = joblib.load(\"scaler.joblib\")\n",
    "\n",
    "# Classifier model\n",
    "hf_hub_download(\"MelioAI/california-housing\", \"model.joblib\")\n",
    "model = joblib.load(\"model.joblib\")\n",
    "```\n",
    "\"\"\"\n",
    "    model_card.add(\n",
    "        folded=False,\n",
    "        **{\n",
    "            \"Model Card Authors\": model_card_authors,\n",
    "            \"Intended uses & limitations\": limitations,\n",
    "            \"Model description\": model_description,\n",
    "            \"Model description/Intended uses & limitations\": limitations,\n",
    "            \"How to Get Started with the Model\": usage_code\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Add tags\n",
    "    model_card.metadata.library_name = \"sklearn\"\n",
    "    model_card.metadata.tags = [\"sklearn\", \"tabular-regression\"]\n",
    "\n",
    "    # Save model card\n",
    "    model_card.save(local_repo / \"README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruan/Documents/github/highwind-examples/california-housing/.train.venv/lib/python3.9/site-packages/skops/hub_utils/_hf_hub.py:577: FutureWarning: Creating repos on hf.co is subject to strict rate limits now and therefore this feature is to be removed from this library in version 0.10. You can use tools directly available in the huggingface_hub library instead to create and push files.\n",
      "  warnings.warn(\n",
      "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "model.joblib: 100%|██████████| 695/695 [00:00<00:00, 1.30kB/s]\n",
      "scaler.joblib: 100%|██████████| 1.22k/1.22k [00:00<00:00, 2.10kB/s]\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:01<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remember to log into HF with the CLI by running: huggingface-cli login\n",
    "if PUSH_TO_HF:\n",
    "\n",
    "    # Push to HF Hub\n",
    "    hub_utils.push(\n",
    "        repo_id=HF_REPO_NAME,\n",
    "        source=local_repo\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) model evaluation\n",
    "\n",
    "Using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove scaler and model from memory to prove loading from disk works\n",
    "del model\n",
    "del scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df: (4128, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "print(f\"test_df: {test_df.shape}\")\n",
    "\n",
    "# Separate features and labels\n",
    "X_test = test_df.copy()\n",
    "y_test = X_test.pop(TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through same preprocessing steps\n",
    "# Feature scaling\n",
    "scaler = joblib.load(os.path.join(ARTIFACT_SAVE_DIR, \"scaler.joblib\"))\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Load model\n",
    "model = joblib.load(os.path.join(ARTIFACT_SAVE_DIR, \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.548\n",
      "RMSE: 0.74\n",
      "-----\n",
      "mean(MedHouseVal): 2.055\n",
      "std(MedHouseVal): 1.145\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "print(f\"MSE: {round(mse, 3)}\")\n",
    "print(f\"RMSE: {round(rmse, 3)}\")\n",
    "print(\"-\"*5)\n",
    "print(f\"mean({TARGET_COLUMN}): {round(y_test.mean(), 3)}\")\n",
    "print(f\"std({TARGET_COLUMN}): {round(y_test.std(), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".train.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
